import tensorflow as tf
import csv
import numpy as np
import pydot
import graphviz

tdf = '../TrainingFiles/SampleTraining2.csv'
ds = 100
e = 500
ed = 2
tc = 23056


def embed(totalCards, embeddingDimensions, deckSize, embedInput):
    embeddingLayer = tf.keras.layers.Embedding(totalCards, embeddingDimensions, input_length=deckSize, trainable=False,
                                               mask_zero=True)
    return embeddingLayer(tf.convert_to_tensor(embedInput))


def prepare_input(fileName, deckSize, maxDecks=None):
    concatData = []
    ratings = []
    embedInput = []

    with open(fileName) as trainingFile:
        reader = csv.reader(trainingFile, delimiter=',')
        first_line = True
        curr_deck = None
        curr_deck_index = 0
        for row in reader:
            if first_line:
                first_line = False
                continue

            index, deck_id, rating, is_commander, count = row

            if curr_deck is None:
                curr_deck = deck_id
                ratings.append(int(rating))
                embedInput.append([])
                concatData.append([])

            if curr_deck != deck_id:
                if int(deck_id) == maxDecks:
                    break
                embedInput[curr_deck_index] = padDeckVector(embedInput[curr_deck_index], deckSize)
                concatData[curr_deck_index] = padConcatVector(concatData[curr_deck_index], deckSize)
                ratings.append(int(rating))
                embedInput.append([])
                concatData.append([])
                curr_deck = deck_id
                curr_deck_index += 1

            # +1 accounting for padding, this should handled in data wrangler, not model
            embedInput[curr_deck_index].append(int(index) + 1)
            concatData[curr_deck_index].append([int(is_commander == "true"), int(count)])

        embedInput[curr_deck_index] = padDeckVector(embedInput[curr_deck_index], deckSize)
        concatData[curr_deck_index] = padConcatVector(concatData[curr_deck_index], deckSize)

    return [np.array(embedInput), np.array(concatData), np.array(ratings)]


def padDeckVector(deckVector, deckSize):
    padAmount = deckSize - len(deckVector)
    return np.array(np.pad(deckVector, (0, padAmount)))


def padConcatVector(concatVector, deckSize):
    padAmount = deckSize - len(concatVector)
    for i in range(padAmount):
        concatVector.append([0, 0])

    return np.array(concatVector)


def buildModel(totalCards, embeddingDimensions, deckSize):
    deck_input = tf.keras.layers.Input(deckSize)
    vector_input = tf.keras.layers.Input((deckSize, 2))
    embeddingLayer = tf.keras.layers.Embedding(totalCards,
                                               embeddingDimensions,
                                               input_length=deckSize,
                                               mask_zero=True)(deck_input)
    concatLayer = tf.keras.layers.Concatenate(axis=2)([embeddingLayer, vector_input])
    x = tf.keras.layers.Dense(1, activation='relu')(concatLayer)
    x = tf.keras.layers.Flatten(data_format=None)(x)
    output = tf.keras.layers.Dense(1, activation='relu')(x)

    model = tf.keras.Model(inputs=[deck_input, vector_input], outputs=output, name="deckorator_model")

    print(model.summary())
    tf.keras.utils.plot_model(model, "model_graph.png")
    tf.keras.utils.plot_model(model, "model_graph_shape_info.png", show_shapes=True)
    return model


def compileModel(model):
    model.compile(loss='mse', optimizer=tf.keras.optimizers.RMSprop(.001), metrics=['mae', 'mse'])


def trainModel(model, trainingData, deckSize, epochs, maxDecks):
    inputData = prepare_input(trainingData, deckSize, maxDecks)
    print("Training with first " + str(len(inputData[0])) + " decks")
    model.fit([inputData[0], inputData[1]], inputData[2], epochs=epochs)


def fullModelSetup(maxDecks):
    model = buildModel(tc, ed, ds)
    compileModel(model)
    trainModel(model, tdf, ds, e, maxDecks)
    return model


def predictHelper(model, inputData, deckIndex):
    deckInput = np.array([inputData[0][deckIndex]])
    concatInput = np.array([inputData[1][deckIndex]])
    return model.predict((deckInput, concatInput))
